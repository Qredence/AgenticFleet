# AI Agent Instructions for AgenticFleet
- **Mental model**: Sequential orchestrator in `src/agenticfleet/workflows/multi_agent.py` drives three specialists (researcher, coder, analyst) created via factories in `src/agenticfleet/agents/*/agent.py`; each factory wraps `ChatAgent` with `OpenAIResponsesClient` and optional tool list.
- **Agent prompts & models**: Every agent pulls its `name`, `model`, and `system_prompt` from `src/agenticfleet/agents/<role>/config.yaml`. Structured changes belong there, not inline in Python.
- **Configuration loader**: `src/agenticfleet/config/settings.py` instantiates at import time; make sure tests or scripts set `OPENAI_API_KEY` plus the Azure endpoints/keys before importing anything from `agenticfleet.config` or `agenticfleet.context`.
- **Workflow contract**: Orchestrator outputs must include `DELEGATE: <agent> - <task>` or `FINAL_ANSWER:` tokens; `MultiAgentWorkflow.run()` enforces `max_rounds` and `max_stalls` from `config/workflow.yaml` and treats repeated responses as stalls.
- **Tools**: Tool modules live under `agents/<role>/tools/` and always return Pydantic models (see `code_interpreter.py` and `web_search_tools.py`). Enable/disable tools by toggling the `tools` array inside each agent’s `config.yaml`.
- **Coder tool specifics**: `code_interpreter_tool` executes Python only, sandboxes builtins, and returns combined stdout/stderr via `CodeExecutionResult`. Add languages by extending the function rather than bypassing the guard.
- **Researcher mocks**: `web_search_tool` currently serves mock responses keyed by query; new search behaviors should preserve the `WebSearchResponse` schema and keep deterministic relevance scoring for tests.
- **Analyst outputs**: `data_analysis_tools.py` exposes both `data_analysis_tool` and `visualization_suggestion_tool`; both share the same Pydantic response contract that downstream code expects.
- **Memory provider**: `Mem0ContextProvider` in `src/agenticfleet/context/mem0_provider.py` requires Azure AI Search + Azure OpenAI env vars; it is exported via `agenticfleet.context` but not yet wired into `MultiAgentWorkflow`, so integrate cautiously and update tests (`tests/test_mem0_context_provider.py`).
- **Logging**: `setup_logging` in `src/agenticfleet/core/logging.py` runs during `Settings` initialization and writes to `logs/agenticfleet.log`; respect the existing LOGGER when adding diagnostics.
- **Error contracts**: Raise `AgentConfigurationError` or `WorkflowError` from `src/agenticfleet/core/exceptions.py` for new config/workflow failures so `tests/test_config.py` stays authoritative.
- **Running the stack**: Use `uv sync` first, then `uv run python tests/test_config.py` (checks 6 configuration categories) before `uv run python main.py` or `uv run python -m agenticfleet`.
- **Test suite**: Broader coverage lives in `uv run pytest -q`; skip external calls by patching `OpenAIResponsesClient` or the tool functions, mirroring existing tests.
- **Formatting & linting**: Stick with `uv run black .` and `uv run ruff check .` (Ruff enforces 100-char lines + Py312 rules per `pyproject.toml`).
- **Package entry**: `src/agenticfleet/__main__.py` dispatches to the same REPL as `main.py`; when adding CLI flags, keep the two entry points synchronized.
- **Adding agents**: Follow the existing directory recipe (factory, config.yaml, tools package, tests) and register the new agent inside `MultiAgentWorkflow` if it participates in delegation.
- **Extending workflow**: Any new orchestration state should live on `MultiAgentWorkflow` and flow through the `context` dict that’s passed to the orchestrator each round to preserve debuggability.
- **Makefile shortcuts**: `make install`, `make test-config`, `make check`, and `make run` mirror the uv commands and are the preferred way to chain tasks locally.
- **Model defaults**: `settings.openai_model` falls back to `gpt-4o-mini`; respect per-agent `model` overrides so preview deployments (for example `gpt-5-codex`) continue to load.
- **Async interfaces**: `ChatAgent.run()` is awaitable; wrap usage in `asyncio.run()` when scripting, and avoid blocking calls inside tools to keep the orchestrator responsive.
- **CI expectations**: GitHub Actions runs Ruff, Black, mypy, and pytest (see `.github/workflows/ci.yml`); replicate that matrix locally before pushing workflow changes.
- **Docs as source**: Architecture and conventions stay current in `docs/overview/implementation-summary.md` and `docs/operations/repository-guidelines.md`; update them when altering patterns so future agents remain consistent.
