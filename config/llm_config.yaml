# LLM Configuration
models:
  o4-mini:
    name: "o4-mini"
    provider: "azure"
    max_tokens: 128000
    temperature_range: [0.3, 0.7]
    default_temperature: 0.7
    streaming: true
    vision: true
    connection_pool_size: 10
    request_timeout: 30
    description: "Azure OpenAI o4-mini Model"
    icon: "public/icons/rocket.svg"

profiles:
  default:
    name: "Magentic Fleet"
    model: "o4-mini"
    description: "Azure OpenAI o4-mini Model"
    icon: "public/icons/rocket.svg"
    ui_render_mode: "tasklist"
    features:
      mcp_enabled: false
      hil_mode: true

mcp:
  agent_coordinator:
    name: "Agent Coordinator MCP"
    description: "Coordinates multiple agents for complex tasks"
    type: "agent_coordinator_mcp"
    max_agents: 10
    default_capabilities:
      - "reasoning"
      - "planning"
      - "execution"

  team_collaboration:
    name: "Team Collaboration MCP"
    description: "Enables collaborative problem-solving among agents"
    type: "agent_coordinator_mcp"
    max_agents: 5
    default_capabilities:
      - "reasoning"
      - "research"
      - "coding"
      - "analysis"
